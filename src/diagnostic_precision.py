#!/usr/bin/env python3
"""
Script de diagnostic pentru a identifica probleme care afecteazÄƒ precizia.
"""

from pathlib import Path
import pandas as pd
import numpy as np

ROOT_DIR = Path(__file__).parent.parent
OUTPUT_DIR = ROOT_DIR / "outputs"

def diagnostic():
    print("=" * 60)
    print("DIAGNOSTIC PRECIZIE - Identificare Probleme")
    print("=" * 60)
    
    # 1. VerificÄƒ datele de bazÄƒ
    print("\n[1] Verificare date de bazÄƒ...")
    
    try:
        tracks_meta = pd.read_csv(OUTPUT_DIR / "tracks_meta.csv")
        train = pd.read_csv(OUTPUT_DIR / "interactions_train.csv")
        test = pd.read_csv(OUTPUT_DIR / "interactions_test.csv")
        recs_als = pd.read_csv(OUTPUT_DIR / "recs_als.csv")
        recs_ae = pd.read_csv(OUTPUT_DIR / "recs_autoencoder.csv")
    except FileNotFoundError as e:
        print(f"    âœ— EROARE: FiÈ™ier lipsÄƒ: {e}")
        return
    
    print(f"    âœ“ Catalog (tracks_meta): {len(tracks_meta):,} piese")
    print(f"    âœ“ Train: {len(train):,} interacÈ›iuni, {train['user_id'].nunique():,} users")
    print(f"    âœ“ Test: {len(test):,} interacÈ›iuni, {test['user_id'].nunique():,} users")
    print(f"    âœ“ ALS recs: {len(recs_als):,} recomandÄƒri")
    print(f"    âœ“ AE recs: {len(recs_ae):,} recomandÄƒri")
    
    # 2. VerificÄƒ overlap train-test (nu ar trebui sÄƒ existe pentru acelaÈ™i user)
    print("\n[2] Verificare overlap train-test per user...")
    
    train_user_tracks = train.groupby('user_id')['track_id'].apply(set).to_dict()
    test_user_tracks = test.groupby('user_id')['track_id'].apply(set).to_dict()
    
    overlaps = 0
    users_with_overlap = 0
    for user_id in train_user_tracks.keys():
        if user_id in test_user_tracks:
            overlap = train_user_tracks[user_id] & test_user_tracks[user_id]
            if overlap:
                overlaps += len(overlap)
                users_with_overlap += 1
    
    if overlaps > 0:
        print(f"    âš   PROBLEMÄ‚: {overlaps} track-uri duplicate Ã®ntre train È™i test pentru {users_with_overlap} users")
        print(f"      â†’ Acest lucru poate afecta evaluarea (itemi din train Ã®n test)")
    else:
        print(f"    âœ“ Nu existÄƒ overlap Ã®ntre train È™i test (OK)")
    
    # 3. VerificÄƒ dacÄƒ track-urile din test sunt Ã®n catalog
    print("\n[3] Verificare track-uri test Ã®n catalog...")
    
    valid_track_ids = set(tracks_meta['id'].tolist())
    test_track_ids = set(test['track_id'].unique())
    train_track_ids = set(train['track_id'].unique())
    
    test_in_catalog = test_track_ids & valid_track_ids
    test_not_in_catalog = test_track_ids - valid_track_ids
    train_in_catalog = train_track_ids & valid_track_ids
    train_not_in_catalog = train_track_ids - valid_track_ids
    
    print(f"    âœ“ Track-uri test Ã®n catalog: {len(test_in_catalog):,} / {len(test_track_ids):,}")
    if len(test_not_in_catalog) > 0:
        print(f"    âš   PROBLEMÄ‚: {len(test_not_in_catalog)} track-uri din test NU sunt Ã®n catalog")
        print(f"      â†’ Acestea nu pot fi evaluate corect")
    
    print(f"    âœ“ Track-uri train Ã®n catalog: {len(train_in_catalog):,} / {len(train_track_ids):,}")
    if len(train_not_in_catalog) > 0:
        print(f"    âš   PROBLEMÄ‚: {len(train_not_in_catalog)} track-uri din train NU sunt Ã®n catalog")
    
    # 4. VerificÄƒ dacÄƒ track-urile recomandate sunt Ã®n catalog
    print("\n[4] Verificare track-uri recomandate Ã®n catalog...")
    
    als_track_ids = set(recs_als['track_id'].unique())
    ae_track_ids = set(recs_ae['track_id'].unique())
    
    als_in_catalog = als_track_ids & valid_track_ids
    als_not_in_catalog = als_track_ids - valid_track_ids
    ae_in_catalog = ae_track_ids & valid_track_ids
    ae_not_in_catalog = ae_track_ids - valid_track_ids
    
    print(f"    âœ“ ALS: {len(als_in_catalog):,} / {len(als_track_ids):,} track-uri Ã®n catalog")
    if len(als_not_in_catalog) > 0:
        print(f"    âš   PROBLEMÄ‚: {len(als_not_in_catalog)} track-uri ALS NU sunt Ã®n catalog")
    
    print(f"    âœ“ Autoencoder: {len(ae_in_catalog):,} / {len(ae_track_ids):,} track-uri Ã®n catalog")
    if len(ae_not_in_catalog) > 0:
        print(f"    âš   PROBLEMÄ‚: {len(ae_not_in_catalog)} track-uri Autoencoder NU sunt Ã®n catalog")
    
    # 5. VerificÄƒ dacÄƒ ALS recomandÄƒ doar track-uri din train
    print("\n[5] Verificare dacÄƒ ALS recomandÄƒ track-uri din train...")
    
    als_only_train = als_track_ids & train_track_ids
    als_not_in_train = als_track_ids - train_track_ids
    
    print(f"    âœ“ ALS recomandÄƒ {len(als_only_train):,} track-uri din train")
    if len(als_not_in_train) > 0:
        print(f"    âš   ATENÈšIE: {len(als_not_in_train)} track-uri ALS NU sunt Ã®n train")
        print(f"      â†’ ALS ar trebui sÄƒ recomande doar track-uri din train")
    else:
        print(f"    âœ“ ALS recomandÄƒ doar track-uri din train (OK)")
    
    # 6. AnalizÄƒ catalog vs test
    print("\n[6] AnalizÄƒ catalog vs test (sparsity)...")
    
    catalog_size = len(tracks_meta)
    test_items_per_user = test.groupby('user_id').size()
    avg_test_items = test_items_per_user.mean()
    
    print(f"    âœ“ Catalog: {catalog_size:,} piese")
    print(f"    âœ“ Test items per user: min={test_items_per_user.min()}, "
          f"mean={avg_test_items:.1f}, max={test_items_per_user.max()}")
    
    # Probabilitatea de a gÄƒsi un item relevant Ã®n top-K (random)
    k_values = [5, 10, 20]
    for k in k_values:
        prob_random = (avg_test_items / catalog_size) * k
        print(f"    â†’ Probabilitate random de a gÄƒsi item relevant Ã®n top-{k}: {prob_random:.4f} ({prob_random*100:.2f}%)")
    
    # 7. VerificÄƒ dacÄƒ existÄƒ useri fÄƒrÄƒ recomandÄƒri
    print("\n[7] Verificare useri fÄƒrÄƒ recomandÄƒri...")
    
    test_users = set(test['user_id'].unique())
    als_users = set(recs_als['user_id'].unique())
    ae_users = set(recs_ae['user_id'].unique())
    
    test_users_no_als = test_users - als_users
    test_users_no_ae = test_users - ae_users
    
    if len(test_users_no_als) > 0:
        print(f"    âš   PROBLEMÄ‚: {len(test_users_no_als)} useri din test NU au recomandÄƒri ALS")
    
    if len(test_users_no_ae) > 0:
        print(f"    âš   PROBLEMÄ‚: {len(test_users_no_ae)} useri din test NU au recomandÄƒri Autoencoder")
    
    if len(test_users_no_als) == 0 and len(test_users_no_ae) == 0:
        print(f"    âœ“ ToÈ›i userii din test au recomandÄƒri (OK)")
    
    # 8. VerificÄƒ numÄƒrul de recomandÄƒri per user
    print("\n[8] Verificare numÄƒr recomandÄƒri per user...")
    
    als_recs_per_user = recs_als.groupby('user_id').size()
    ae_recs_per_user = recs_ae.groupby('user_id').size()
    
    print(f"    âœ“ ALS: min={als_recs_per_user.min()}, mean={als_recs_per_user.mean():.1f}, max={als_recs_per_user.max()}")
    print(f"    âœ“ Autoencoder: min={ae_recs_per_user.min()}, mean={ae_recs_per_user.mean():.1f}, max={ae_recs_per_user.max()}")
    
    # 9. VerificÄƒ dacÄƒ existÄƒ track-uri din test care pot fi gÄƒsite Ã®n recomandÄƒri
    print("\n[9] AnalizÄƒ potenÈ›ial de matching test-recomandÄƒri...")
    
    # Pentru fiecare user, verificÄƒ cÃ¢te track-uri din test sunt Ã®n recomandÄƒri
    test_truth = test.groupby('user_id')['track_id'].apply(set).to_dict()
    
    als_matches = []
    ae_matches = []
    
    for user_id in test_truth.keys():
        truth_set = test_truth[user_id]
        
        if user_id in als_users:
            als_user_recs = set(recs_als[recs_als['user_id'] == user_id]['track_id'].tolist())
            matches = truth_set & als_user_recs
            als_matches.append(len(matches))
        
        if user_id in ae_users:
            ae_user_recs = set(recs_ae[recs_ae['user_id'] == user_id]['track_id'].tolist())
            matches = truth_set & ae_user_recs
            ae_matches.append(len(matches))
    
    if als_matches:
        print(f"    âœ“ ALS: {np.mean(als_matches):.2f} matches per user Ã®n medie "
              f"(max={max(als_matches) if als_matches else 0})")
        print(f"      â†’ Users cu â‰¥1 match: {sum(1 for m in als_matches if m > 0)} / {len(als_matches)}")
    
    if ae_matches:
        print(f"    âœ“ Autoencoder: {np.mean(ae_matches):.2f} matches per user Ã®n medie "
              f"(max={max(ae_matches) if ae_matches else 0})")
        print(f"      â†’ Users cu â‰¥1 match: {sum(1 for m in ae_matches if m > 0)} / {len(ae_matches)}")
    
    # 10. Rezumat probleme identificate
    print("\n" + "=" * 60)
    print("REZUMAT PROBLEME IDENTIFICATE:")
    print("=" * 60)
    
    problems = []
    
    if overlaps > 0:
        problems.append(f"âš   {overlaps} track-uri duplicate Ã®ntre train È™i test")
    
    if len(test_not_in_catalog) > 0:
        problems.append(f"âš   {len(test_not_in_catalog)} track-uri din test NU sunt Ã®n catalog")
    
    if len(als_not_in_train) > 0:
        problems.append(f"âš   {len(als_not_in_train)} track-uri ALS NU sunt Ã®n train")
    
    if len(test_users_no_als) > 0:
        problems.append(f"âš   {len(test_users_no_als)} useri din test fÄƒrÄƒ recomandÄƒri ALS")
    
    if len(test_users_no_ae) > 0:
        problems.append(f"âš   {len(test_users_no_ae)} useri din test fÄƒrÄƒ recomandÄƒri Autoencoder")
    
    if catalog_size > 20000:
        problems.append(f"âš   Catalog prea mare ({catalog_size:,} piese) - reduce precizia")
    
    if len(problems) == 0:
        print("âœ“ Nu s-au identificat probleme majore Ã®n logica de recomandare/evaluare")
        print("\nðŸ’¡ SUGESTIE: Precizia scÄƒzutÄƒ este probabil cauzatÄƒ de:")
        print(f"   - Catalog prea mare ({catalog_size:,} piese)")
        print(f"   - Prea puÈ›ine itemi relevanÈ›i Ã®n test per user ({avg_test_items:.1f} Ã®n medie)")
        print(f"   - Probabilitate random de matching: {prob_random:.4f} pentru top-10")
    else:
        for problem in problems:
            print(problem)
    
    print("\nðŸ’¡ RECOMANDÄ‚RI:")
    print("   1. MÄƒreÈ™te MIN_POPULARITY Ã®n prepare_data.py (ex: 50-60)")
    print("   2. Sau filtreazÄƒ catalogul la track-uri care apar Ã®n train")
    print("   3. Sau mÄƒreÈ™te K (numÄƒrul de recomandÄƒri) la 500-1000")
    print("=" * 60)

if __name__ == "__main__":
    try:
        diagnostic()
    except Exception as e:
        print(f"\nâœ— EROARE: {e}")
        import traceback
        traceback.print_exc()
